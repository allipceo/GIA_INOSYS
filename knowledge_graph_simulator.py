#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GIA_INFOSYS ì§€ì‹ ê·¸ë˜í”„ ë° ì¸ì‚¬ì´íŠ¸ ì‹œìŠ¤í…œ ì‹œë®¬ë ˆì´í„°
Phase 2-2, ê³¼ì—… 1: ì§€ì‹ ê·¸ë˜í”„ ë° ì¸ì‚¬ì´íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶•

ì‘ì„±ì¼: 2025ë…„ 8ì›” 22ì¼
ì‘ì„±ì: ì„œëŒ€ë¦¬ (Lead Developer)
ëª©ì : ê°œì²´ ì •ë³´ DB, ê´€ê³„í˜• ì—°ê²°, ì¸ì‚¬ì´íŠ¸ ìƒì„± ê¸°ëŠ¥ ì‹œë®¬ë ˆì´ì…˜
"""

import os
import sys
import json
from datetime import datetime
from typing import Dict, Any, List, Optional

# í™˜ê²½ ë³€ìˆ˜
from dotenv import load_dotenv

# ë¡œê¹… ì„¤ì •
import logging

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ (ì¸ì½”ë”© ì˜¤ë¥˜ ë¬´ì‹œ)
try:
    load_dotenv(encoding='utf-8')
except Exception as e:
    logging.warning(f"Failed to load .env with utf-8, trying default: {e}")
    load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('knowledge_graph_simulator.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

class EntityInfo:
    """ê°œì²´ ì •ë³´ í´ë˜ìŠ¤"""
    
    def __init__(self, name: str, entity_type: str, related_docs: List[str] = None):
        self.name = name
        self.entity_type = entity_type
        self.related_docs = related_docs or []
        self.created_at = datetime.now()
        self.insights = []
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "type": self.entity_type,
            "related_docs": self.related_docs,
            "doc_count": len(self.related_docs),
            "created_at": self.created_at.isoformat(),
            "insights": self.insights
        }

class KnowledgeGraphSimulator:
    """ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´í„° í´ë˜ìŠ¤"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.entities_db = {}  # ê°œì²´ ì •ë³´ DB ì‹œë®¬ë ˆì´ì…˜
        self.documents_db = {}  # ë¬¸ì„œ DB ì‹œë®¬ë ˆì´ì…˜
        self.relationships = {}  # ê´€ê³„í˜• ì—°ê²° ì‹œë®¬ë ˆì´ì…˜
        self.insights_history = []  # ì¸ì‚¬ì´íŠ¸ íˆìŠ¤í† ë¦¬
        
        # ê°œì²´ ìœ í˜• ì •ì˜
        self.entity_types = ["ì¸ë¬¼", "ê¸°ì—…", "ê¸°ìˆ ", "ì •ì±…", "ì´ë²¤íŠ¸", "ìœ„í—˜", "í”„ë¡œì íŠ¸"]
        
        logger.info("ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
    
    def create_entity_database(self) -> Dict[str, Any]:
        """
        ê°œì²´ ì •ë³´ DB ìƒì„± ì‹œë®¬ë ˆì´ì…˜
        
        Returns:
            Dict[str, Any]: DB ìƒì„± ê²°ê³¼
        """
        logger.info("=== ê°œì²´ ì •ë³´ DB ìƒì„± ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘ ===")
        
        db_structure = {
            "database_name": "ê°œì²´ ì •ë³´ DB",
            "workspace": "GIA_INFOSYS",
            "properties": {
                "ì´ë¦„": {"type": "Title", "description": "ê°œì²´ì˜ ì´ë¦„"},
                "ìœ í˜•": {"type": "Select", "options": self.entity_types},
                "ê´€ë ¨ ë¬¸ì„œ": {"type": "Relation", "target_db": "ì„ì‹œ í…ŒìŠ¤íŠ¸ìš© DB"},
                "ë¬¸ì„œ ê°œìˆ˜": {"type": "Rollup", "function": "count", "relation_property": "ê´€ë ¨ ë¬¸ì„œ"},
                "ìƒì„±ì¼": {"type": "Date"},
                "ìµœê·¼ ì—…ë°ì´íŠ¸": {"type": "Date"}
            },
            "status": "created",
            "created_at": datetime.now().isoformat()
        }
        
        logger.info(f"ê°œì²´ ì •ë³´ DB ìƒì„± ì„±ê³µ: {db_structure['database_name']}")
        logger.info(f"ì†ì„± ê°œìˆ˜: {len(db_structure['properties'])}")
        
        return db_structure
    
    def extract_entities_from_text(self, text: str, doc_id: str) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ê°œì²´ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜ (ì‹œë®¬ë ˆì´ì…˜)
        
        Args:
            text (str): ë¶„ì„í•  í…ìŠ¤íŠ¸
            doc_id (str): ë¬¸ì„œ ID
            
        Returns:
            List[Dict[str, Any]]: ì¶”ì¶œëœ ê°œì²´ ëª©ë¡
        """
        logger.info(f"í…ìŠ¤íŠ¸ì—ì„œ ê°œì²´ ì¶”ì¶œ ì‹œì‘: ë¬¸ì„œ {doc_id}")
        
        # ì‹œë®¬ë ˆì´ì…˜ëœ ê°œì²´ ì¶”ì¶œ
        extracted_entities = [
            {"name": "ì¡°ëŒ€í‘œ", "type": "ì¸ë¬¼", "confidence": 0.95},
            {"name": "GIA_INFOSYS", "type": "í”„ë¡œì íŠ¸", "confidence": 0.90},
            {"name": "Notion", "type": "ê¸°ìˆ ", "confidence": 0.85},
            {"name": "AI ê¸°ìˆ ", "type": "ê¸°ìˆ ", "confidence": 0.80},
            {"name": "ê°œì¸ì •ë³´ì‹œìŠ¤í…œ", "type": "í”„ë¡œì íŠ¸", "confidence": 0.75}
        ]
        
        logger.info(f"ê°œì²´ ì¶”ì¶œ ì™„ë£Œ: {len(extracted_entities)}ê°œ ê°œì²´ ë°œê²¬")
        return extracted_entities
    
    def create_or_update_entity(self, entity_data: Dict[str, Any], doc_id: str) -> str:
        """
        ê°œì²´ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            entity_data (Dict[str, Any]): ê°œì²´ ë°ì´í„°
            doc_id (str): ê´€ë ¨ ë¬¸ì„œ ID
            
        Returns:
            str: ê°œì²´ ID
        """
        entity_name = entity_data["name"]
        entity_type = entity_data["type"]
        
        if entity_name in self.entities_db:
            # ê¸°ì¡´ ê°œì²´ ì—…ë°ì´íŠ¸
            entity = self.entities_db[entity_name]
            if doc_id not in entity.related_docs:
                entity.related_docs.append(doc_id)
            logger.info(f"ê¸°ì¡´ ê°œì²´ ì—…ë°ì´íŠ¸: {entity_name}")
        else:
            # ìƒˆ ê°œì²´ ìƒì„±
            entity = EntityInfo(entity_name, entity_type, [doc_id])
            self.entities_db[entity_name] = entity
            logger.info(f"ìƒˆ ê°œì²´ ìƒì„±: {entity_name} ({entity_type})")
        
        return entity_name
    
    def create_relationships(self, doc_id: str, entities: List[str]) -> Dict[str, Any]:
        """
        ê´€ê³„í˜• ì—°ê²°ì„ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            doc_id (str): ë¬¸ì„œ ID
            entities (List[str]): ê´€ë ¨ ê°œì²´ ëª©ë¡
            
        Returns:
            Dict[str, Any]: ê´€ê³„ ìƒì„± ê²°ê³¼
        """
        logger.info(f"ê´€ê³„í˜• ì—°ê²° ìƒì„±: ë¬¸ì„œ {doc_id}ì™€ {len(entities)}ê°œ ê°œì²´")
        
        relationships = {
            "document_id": doc_id,
            "related_entities": entities,
            "relationship_count": len(entities),
            "created_at": datetime.now().isoformat()
        }
        
        self.relationships[doc_id] = relationships
        logger.info(f"ê´€ê³„í˜• ì—°ê²° ìƒì„± ì™„ë£Œ: {len(entities)}ê°œ ì—°ê²°")
        
        return relationships
    
    def generate_insights(self, entities: List[str]) -> List[Dict[str, Any]]:
        """
        ê°œì²´ë“¤ì„ ê¸°ë°˜ìœ¼ë¡œ ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            entities (List[str]): ë¶„ì„í•  ê°œì²´ ëª©ë¡
            
        Returns:
            List[Dict[str, Any]]: ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸ ëª©ë¡
        """
        logger.info(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì‹œì‘: {len(entities)}ê°œ ê°œì²´ ë¶„ì„")
        
        insights = []
        
        # ì‹œë®¬ë ˆì´ì…˜ëœ ì¸ì‚¬ì´íŠ¸ ìƒì„±
        if "ì¡°ëŒ€í‘œ" in entities and "GIA_INFOSYS" in entities:
            insights.append({
                "type": "ì—°ê´€ì„± ë¶„ì„",
                "content": "ì¡°ëŒ€í‘œë‹˜ì˜ GIA_INFOSYS í”„ë¡œì íŠ¸ëŠ” ê°œì¸ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ì˜ í•µì‹¬ í”„ë¡œì íŠ¸ë¡œ, AI ê¸°ìˆ ê³¼ Notionì„ ê²°í•©í•œ í˜ì‹ ì  ì ‘ê·¼ë²•ì„ ë³´ì—¬ì¤ë‹ˆë‹¤.",
                "confidence": 0.85,
                "entities_involved": ["ì¡°ëŒ€í‘œ", "GIA_INFOSYS", "AI ê¸°ìˆ ", "Notion"],
                "generated_at": datetime.now().isoformat()
            })
        
        if "Notion" in entities and "AI ê¸°ìˆ " in entities:
            insights.append({
                "type": "ê¸°ìˆ  ìœµí•©",
                "content": "Notionê³¼ AI ê¸°ìˆ ì˜ ê²°í•©ì€ ì§€ì‹ ê´€ë¦¬ì˜ ìƒˆë¡œìš´ íŒ¨ëŸ¬ë‹¤ì„ì„ ì œì‹œí•˜ë©°, ìë™í™”ëœ ì¸ì‚¬ì´íŠ¸ ìƒì„±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.",
                "confidence": 0.80,
                "entities_involved": ["Notion", "AI ê¸°ìˆ "],
                "generated_at": datetime.now().isoformat()
            })
        
        if "ê°œì¸ì •ë³´ì‹œìŠ¤í…œ" in entities:
            insights.append({
                "type": "ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜",
                "content": "ê°œì¸ì •ë³´ì‹œìŠ¤í…œì€ ë¶„ì‚°ëœ ì •ë³´ë¥¼ í†µí•©í•˜ê³  ì˜ë¯¸ìˆëŠ” ì—°ê²°ì„ í†µí•´ ì§€ì‹ìœ¼ë¡œ ì „í™˜í•˜ëŠ” ê²ƒì´ í•µì‹¬ì…ë‹ˆë‹¤.",
                "confidence": 0.75,
                "entities_involved": ["ê°œì¸ì •ë³´ì‹œìŠ¤í…œ"],
                "generated_at": datetime.now().isoformat()
            })
        
        # ì¸ì‚¬ì´íŠ¸ íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.insights_history.extend(insights)
        
        logger.info(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì™„ë£Œ: {len(insights)}ê°œ ì¸ì‚¬ì´íŠ¸ ìƒì„±")
        return insights
    
    def get_entity_statistics(self) -> Dict[str, Any]:
        """
        ê°œì²´ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
        
        Returns:
            Dict[str, Any]: í†µê³„ ì •ë³´
        """
        stats = {
            "total_entities": len(self.entities_db),
            "entity_types": {},
            "most_connected_entity": None,
            "total_relationships": len(self.relationships),
            "total_insights": len(self.insights_history)
        }
        
        # ê°œì²´ ìœ í˜•ë³„ í†µê³„
        for entity in self.entities_db.values():
            entity_type = entity.entity_type
            if entity_type not in stats["entity_types"]:
                stats["entity_types"][entity_type] = 0
            stats["entity_types"][entity_type] += 1
        
        # ê°€ì¥ ë§ì´ ì—°ê²°ëœ ê°œì²´ ì°¾ê¸°
        max_connections = 0
        for entity_name, entity in self.entities_db.items():
            if len(entity.related_docs) > max_connections:
                max_connections = len(entity.related_docs)
                stats["most_connected_entity"] = {
                    "name": entity_name,
                    "type": entity.entity_type,
                    "connection_count": max_connections
                }
        
        return stats
    
    def simulate_document_processing(self, doc_title: str, doc_content: str) -> Dict[str, Any]:
        """
        ë¬¸ì„œ ì²˜ë¦¬ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ëŠ” í†µí•© í•¨ìˆ˜
        
        Args:
            doc_title (str): ë¬¸ì„œ ì œëª©
            doc_content (str): ë¬¸ì„œ ë‚´ìš©
            
        Returns:
            Dict[str, Any]: ì²˜ë¦¬ ê²°ê³¼
        """
        logger.info(f"=== ë¬¸ì„œ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘: {doc_title} ===")
        
        # ë¬¸ì„œ ID ìƒì„±
        doc_id = f"doc_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{hash(doc_title) % 10000}"
        
        # 1. ê°œì²´ ì¶”ì¶œ
        extracted_entities = self.extract_entities_from_text(doc_content, doc_id)
        
        # 2. ê°œì²´ ìƒì„±/ì—…ë°ì´íŠ¸
        entity_names = []
        for entity_data in extracted_entities:
            entity_name = self.create_or_update_entity(entity_data, doc_id)
            entity_names.append(entity_name)
        
        # 3. ê´€ê³„í˜• ì—°ê²° ìƒì„±
        relationships = self.create_relationships(doc_id, entity_names)
        
        # 4. ì¸ì‚¬ì´íŠ¸ ìƒì„±
        insights = self.generate_insights(entity_names)
        
        # 5. ê²°ê³¼ ë°˜í™˜
        result = {
            "document": {
                "id": doc_id,
                "title": doc_title,
                "content_length": len(doc_content)
            },
            "entities": extracted_entities,
            "relationships": relationships,
            "insights": insights,
            "processing_time": datetime.now().isoformat()
        }
        
        logger.info(f"ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {doc_title}")
        return result

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== GIA_INFOSYS ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´í„° ì‹œì‘ ===")
    
    # ì‹œë®¬ë ˆì´í„° ì´ˆê¸°í™”
    simulator = KnowledgeGraphSimulator()
    
    # 1. ê°œì²´ ì •ë³´ DB ìƒì„±
    db_result = simulator.create_entity_database()
    print(f"\nâœ… ê°œì²´ ì •ë³´ DB ìƒì„± ì™„ë£Œ: {db_result['database_name']}")
    
    # 2. ìƒ˜í”Œ ë¬¸ì„œ ì²˜ë¦¬
    sample_documents = [
        {
            "title": "GIA_INFOSYS í”„ë¡œì íŠ¸ ê¸°íšì„œ",
            "content": "ì¡°ëŒ€í‘œë‹˜ì˜ ê°œì¸ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ GIA_INFOSYS í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤. Notionê³¼ AI ê¸°ìˆ ì„ í™œìš©í•˜ì—¬ ë¶„ì‚°ëœ ì •ë³´ë¥¼ í†µí•©í•˜ê³  ì§€ì‹ìœ¼ë¡œ ì „í™˜í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤."
        },
        {
            "title": "AI ê¸°ìˆ  ì ìš© ë°©ì•ˆ",
            "content": "Notion APIì™€ Gemini Pro APIë¥¼ ì—°ë™í•˜ì—¬ ë¬¸ì„œì—ì„œ ì˜ë¯¸ë¥¼ ì¶”ì¶œí•˜ê³ , ì§€ì‹ ê·¸ë˜í”„ë¥¼ êµ¬ì¶•í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ë¥¼ ìë™ ìƒì„±í•˜ëŠ” ì‹œìŠ¤í…œì„ ê°œë°œí•©ë‹ˆë‹¤."
        },
        {
            "title": "ê°œì¸ì •ë³´ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜",
            "content": "ì¡°ëŒ€í‘œë‹˜ì˜ êµ¬ê¸€ ë“œë¼ì´ë¸Œ, ì›ë“œë¼ì´ë¸Œ, ì´ë©”ì¼ ë“± ë¶„ì‚°ëœ ì •ë³´ë¥¼ Notionìœ¼ë¡œ í†µí•©í•˜ê³ , AI ê¸°ë°˜ ë¶„ì„ì„ í†µí•´ ì§€ì‹ìœ¼ë¡œ ì „í™˜í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤."
        }
    ]
    
    print(f"\nğŸ“„ {len(sample_documents)}ê°œ ìƒ˜í”Œ ë¬¸ì„œ ì²˜ë¦¬ ì‹œì‘...")
    
    processing_results = []
    for doc in sample_documents:
        result = simulator.simulate_document_processing(doc["title"], doc["content"])
        processing_results.append(result)
        print(f"  âœ… {doc['title']} ì²˜ë¦¬ ì™„ë£Œ")
    
    # 3. í†µê³„ ì •ë³´ ì¶œë ¥
    stats = simulator.get_entity_statistics()
    print(f"\nğŸ“Š ì§€ì‹ ê·¸ë˜í”„ í†µê³„:")
    print(f"  - ì´ ê°œì²´ ìˆ˜: {stats['total_entities']}")
    print(f"  - ì´ ê´€ê³„ ìˆ˜: {stats['total_relationships']}")
    print(f"  - ì´ ì¸ì‚¬ì´íŠ¸ ìˆ˜: {stats['total_insights']}")
    print(f"  - ê°œì²´ ìœ í˜•ë³„ ë¶„í¬: {stats['entity_types']}")
    
    if stats['most_connected_entity']:
        most_connected = stats['most_connected_entity']
        print(f"  - ê°€ì¥ ë§ì´ ì—°ê²°ëœ ê°œì²´: {most_connected['name']} ({most_connected['connection_count']}ê°œ ì—°ê²°)")
    
    # 4. ì¸ì‚¬ì´íŠ¸ ìš”ì•½
    print(f"\nğŸ’¡ ìƒì„±ëœ ì¸ì‚¬ì´íŠ¸ ìš”ì•½:")
    for i, insight in enumerate(simulator.insights_history, 1):
        print(f"  {i}. [{insight['type']}] {insight['content']}")
    
    print(f"\nğŸ‰ ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
    print(f"ë‹¤ìŒ ë‹¨ê³„: notion_uploader_v3.py ê°œë°œ ë° ì‹¤ì œ Notion ì—°ë™")
    
    return {
        "success": True,
        "database_created": True,
        "documents_processed": len(processing_results),
        "entities_created": stats['total_entities'],
        "insights_generated": stats['total_insights'],
        "relationships_created": stats['total_relationships']
    }

if __name__ == "__main__":
    main()

