#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
GIA_INFOSYS ì§€ì‹ ê·¸ë˜í”„ í†µí•© í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
Phase 2-2, ê³¼ì—… 1: ì§€ì‹ ê·¸ë˜í”„ ë° ì¸ì‚¬ì´íŠ¸ ì‹œìŠ¤í…œ í†µí•© í…ŒìŠ¤íŠ¸

ì‘ì„±ì¼: 2025ë…„ 8ì›” 22ì¼
ì‘ì„±ì: ì„œëŒ€ë¦¬ (Lead Developer)
ëª©ì : ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´í„°ì™€ Notion ì—…ë¡œë” v3ì˜ í†µí•© í…ŒìŠ¤íŠ¸
"""

import os
import sys
import json
from datetime import datetime
from typing import Dict, Any, List

# ë¡œê¹… ì„¤ì •
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('knowledge_graph_integration_test.log', encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)

def run_knowledge_graph_simulator_test():
    """ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´í„° í…ŒìŠ¤íŠ¸"""
    logger.info("=== ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´í„° í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        from knowledge_graph_simulator import KnowledgeGraphSimulator
        
        simulator = KnowledgeGraphSimulator()
        
        # 1. DB ìƒì„± í…ŒìŠ¤íŠ¸
        db_result = simulator.create_entity_database()
        logger.info(f"DB ìƒì„± í…ŒìŠ¤íŠ¸ ê²°ê³¼: {db_result['database_name']}")
        
        # 2. ë¬¸ì„œ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
        test_docs = [
            {
                "title": "GIA_INFOSYS í”„ë¡œì íŠ¸ ê¸°íšì„œ",
                "content": "ì¡°ëŒ€í‘œë‹˜ì˜ ê°œì¸ì •ë³´ì‹œìŠ¤í…œ êµ¬ì¶•ì„ ìœ„í•œ GIA_INFOSYS í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤."
            },
            {
                "title": "AI ê¸°ìˆ  ì ìš© ë°©ì•ˆ",
                "content": "Notion APIì™€ Gemini Pro APIë¥¼ ì—°ë™í•˜ì—¬ ë¬¸ì„œì—ì„œ ì˜ë¯¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤."
            }
        ]
        
        processing_results = []
        for doc in test_docs:
            result = simulator.simulate_document_processing(doc["title"], doc["content"])
            processing_results.append(result)
            logger.info(f"ë¬¸ì„œ ì²˜ë¦¬ ì™„ë£Œ: {doc['title']}")
        
        # 3. í†µê³„ í™•ì¸
        stats = simulator.get_entity_statistics()
        logger.info(f"í†µê³„ ì •ë³´: {stats}")
        
        return {
            "success": True,
            "database_created": True,
            "documents_processed": len(processing_results),
            "entities_created": stats['total_entities'],
            "insights_generated": stats['total_insights']
        }
        
    except Exception as e:
        logger.error(f"ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´í„° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return {"success": False, "error": str(e)}

def run_notion_uploader_v3_test():
    """Notion ì—…ë¡œë” v3 í…ŒìŠ¤íŠ¸"""
    logger.info("=== Notion ì—…ë¡œë” v3 í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    try:
        from notion_uploader_v3 import NotionUploaderV3
        
        uploader = NotionUploaderV3()
        results = uploader.run_knowledge_graph_pipeline()
        
        logger.info(f"ì—…ë¡œë” v3 í…ŒìŠ¤íŠ¸ ê²°ê³¼: {results}")
        
        return results
        
    except Exception as e:
        logger.error(f"Notion ì—…ë¡œë” v3 í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return {"success": False, "error": str(e)}

def run_integration_test():
    """í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    logger.info("=== ì§€ì‹ ê·¸ë˜í”„ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # 1. ì§€ì‹ ê·¸ë˜í”„ ì‹œë®¬ë ˆì´í„° í…ŒìŠ¤íŠ¸
    simulator_result = run_knowledge_graph_simulator_test()
    
    # 2. Notion ì—…ë¡œë” v3 í…ŒìŠ¤íŠ¸
    uploader_result = run_notion_uploader_v3_test()
    
    # 3. í†µí•© ê²°ê³¼ ë¶„ì„
    overall_success = simulator_result.get('success', False) and uploader_result.get('success', False)
    
    integration_result = {
        "overall_success": overall_success,
        "simulator_test": simulator_result,
        "uploader_test": uploader_result,
        "test_timestamp": datetime.now().isoformat()
    }
    
    logger.info(f"í†µí•© í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {'ì„±ê³µ' if overall_success else 'ì‹¤íŒ¨'}")
    
    return integration_result

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("=== GIA_INFOSYS ì§€ì‹ ê·¸ë˜í”„ í†µí•© í…ŒìŠ¤íŠ¸ ì‹œì‘ ===")
    
    # í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    result = run_integration_test()
    
    print("\n=== í†µí•© í…ŒìŠ¤íŠ¸ ê²°ê³¼ ===")
    print(f"ì „ì²´ ì„±ê³µ: {'âœ… ì„±ê³µ' if result['overall_success'] else 'âŒ ì‹¤íŒ¨'}")
    
    print(f"\nğŸ“Š ì‹œë®¬ë ˆì´í„° í…ŒìŠ¤íŠ¸:")
    simulator = result['simulator_test']
    if simulator.get('success'):
        print(f"  âœ… DB ìƒì„±: ì„±ê³µ")
        print(f"  âœ… ë¬¸ì„œ ì²˜ë¦¬: {simulator.get('documents_processed', 0)}ê°œ")
        print(f"  âœ… ê°œì²´ ìƒì„±: {simulator.get('entities_created', 0)}ê°œ")
        print(f"  âœ… ì¸ì‚¬ì´íŠ¸ ìƒì„±: {simulator.get('insights_generated', 0)}ê°œ")
    else:
        print(f"  âŒ ì‹¤íŒ¨: {simulator.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    
    print(f"\nğŸ“Š ì—…ë¡œë” v3 í…ŒìŠ¤íŠ¸:")
    uploader = result['uploader_test']
    if uploader.get('success'):
        print(f"  âœ… íŒŒì´í”„ë¼ì¸ ì‹¤í–‰: ì„±ê³µ")
        print(f"  âœ… íŒŒì¼ ì²˜ë¦¬: {uploader.get('success_count', 0)}/{uploader.get('total_files', 0)}")
        print(f"  âœ… ì´ ê°œì²´: {uploader.get('total_entities', 0)}ê°œ")
        print(f"  âœ… ì´ ì¸ì‚¬ì´íŠ¸: {uploader.get('total_insights', 0)}ê°œ")
    else:
        print(f"  âŒ ì‹¤íŒ¨: {uploader.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    
    print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼: {'ğŸ‰ ì§€ì‹ ê·¸ë˜í”„ ì‹œìŠ¤í…œ í†µí•© ì„±ê³µ!' if result['overall_success'] else 'âš ï¸ í†µí•© í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨!'}")
    
    return result['overall_success']

if __name__ == "__main__":
    main()
