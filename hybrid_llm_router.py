#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
í•˜ì´ë¸Œë¦¬ë“œ LLM ë¼ìš°í„°
ë…¸íŠ¸ë¶LMê³¼ Gemini Proë¥¼ ê²°í•©í•˜ì—¬ ë¬¸ì„œì˜ ë¯¼ê°ë„ì— ë”°ë¼ ìµœì ì˜ LLM ì„ íƒ
"""

import os
import json
import re
from datetime import datetime
from typing import Dict, Any, List
from dotenv import load_dotenv

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
try:
    load_dotenv()
except UnicodeDecodeError:
    load_dotenv(encoding='utf-8')

class HybridLLMRouter:
    def __init__(self):
        self.gemini_api_key_1 = os.getenv('GEMINI_API_KEY_1')
        self.gemini_api_key_2 = os.getenv('GEMINI_API_KEY_2')
        self.sensitivity_keywords = {
            "high": ["ë¹„ë°€", "ê¸°ë°€", "ë‚´ë¶€", "ì „ëµ", "ì¬ë¬´", "ì¸ì‚¬", "ê³„ì•½", "íŠ¹í—ˆ"],
            "medium": ["ë¶„ì„", "ë³´ê³ ì„œ", "ê²€í† ", "í‰ê°€", "ì œì•ˆ", "ê³„íš"],
            "low": ["ë‰´ìŠ¤", "ê³µê°œ", "ì¼ë°˜", "ì°¸ê³ ", "ì •ë³´"]
        }
        
    def analyze_sensitivity(self, text: str) -> Dict[str, Any]:
        """ë¬¸ì„œì˜ ë¯¼ê°ë„ë¥¼ ë¶„ì„"""
        print("ğŸ” ë¬¸ì„œ ë¯¼ê°ë„ ë¶„ì„ ì¤‘...")
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ë¯¼ê°ë„ ë¶„ì„
        high_count = sum(1 for keyword in self.sensitivity_keywords["high"] if keyword in text)
        medium_count = sum(1 for keyword in self.sensitivity_keywords["medium"] if keyword in text)
        low_count = sum(1 for keyword in self.sensitivity_keywords["low"] if keyword in text)
        
        # ë¯¼ê°ë„ ì ìˆ˜ ê³„ì‚° (1-10ì )
        sensitivity_score = 0
        
        if high_count > 0:
            sensitivity_score = 8 + min(high_count, 2)  # 8-10ì 
        elif medium_count > 0:
            sensitivity_score = 4 + min(medium_count, 3)  # 4-7ì 
        elif low_count > 0:
            sensitivity_score = 1 + min(low_count, 2)  # 1-3ì 
        else:
            sensitivity_score = 5  # ê¸°ë³¸ê°’
        
        # ë¯¼ê°ë„ ë ˆë²¨ ê²°ì •
        if sensitivity_score >= 8:
            level = "high"
            recommended_llm = "notebooklm"
        elif sensitivity_score >= 4:
            level = "medium"
            recommended_llm = "hybrid"
        else:
            level = "low"
            recommended_llm = "gemini_pro"
        
        analysis_result = {
            "sensitivity_score": sensitivity_score,
            "sensitivity_level": level,
            "recommended_llm": recommended_llm,
            "keyword_counts": {
                "high": high_count,
                "medium": medium_count,
                "low": low_count
            },
            "analysis_timestamp": datetime.now().isoformat()
        }
        
        print(f"âœ… ë¯¼ê°ë„ ë¶„ì„ ì™„ë£Œ: {sensitivity_score}ì  ({level})")
        print(f"ğŸ¯ ê¶Œì¥ LLM: {recommended_llm}")
        
        return analysis_result
    
    def route_to_llm(self, text: str, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ì— ë”°ë¼ ì ì ˆí•œ LLMìœ¼ë¡œ ë¼ìš°íŒ…"""
        print("ğŸ”„ LLM ë¼ìš°íŒ… ì¤‘...")
        
        recommended_llm = analysis_result["recommended_llm"]
        
        if recommended_llm == "notebooklm":
            return self.process_with_notebooklm(text, analysis_result)
        elif recommended_llm == "gemini_pro":
            return self.process_with_gemini_pro(text, analysis_result)
        else:  # hybrid
            return self.process_with_hybrid(text, analysis_result)
    
    def process_with_notebooklm(self, text: str, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """ë…¸íŠ¸ë¶LMìœ¼ë¡œ ì²˜ë¦¬ (ê³ ë¯¼ê°ë„ ë¬¸ì„œ)"""
        print("ğŸ“± ë…¸íŠ¸ë¶LMìœ¼ë¡œ ì²˜ë¦¬ ì¤‘...")
        
        # ì‹œë®¬ë ˆì´ì…˜: ë…¸íŠ¸ë¶LM ì²˜ë¦¬
        result = {
            "llm_used": "notebooklm",
            "processing_type": "local_secure",
            "extracted_data": {
                "keywords": ["ë‚´ë¶€ì „ëµ", "ê¸°ë°€ì •ë³´", "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸"],
                "summary": "ê³ ë¯¼ê°ë„ ë¬¸ì„œë¡œ ì¸ì‹ë˜ì–´ ë…¸íŠ¸ë¶LMì—ì„œ ë¡œì»¬ ì²˜ë¦¬ë¨",
                "entities": ["ë‚´ë¶€ì¸ë¬¼1", "ë‚´ë¶€ì¸ë¬¼2"],
                "insights": "ê°œì¸ ê²½í—˜ ê¸°ë°˜ ë¶„ì„ìœ¼ë¡œ ì°½ì˜ì  ì¸ì‚¬ì´íŠ¸ ìƒì„±"
            },
            "security_level": "maximum",
            "processing_time": "2.3ì´ˆ",
            "analysis_result": analysis_result
        }
        
        print("âœ… ë…¸íŠ¸ë¶LM ì²˜ë¦¬ ì™„ë£Œ")
        return result
    
    def process_with_gemini_pro(self, text: str, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """Gemini Proë¡œ ì²˜ë¦¬ (ì €ë¯¼ê°ë„ ë¬¸ì„œ)"""
        print("â˜ï¸ Gemini Proë¡œ ì²˜ë¦¬ ì¤‘...")
        
        # ì‹œë®¬ë ˆì´ì…˜: Gemini Pro ì²˜ë¦¬
        result = {
            "llm_used": "gemini_pro",
            "processing_type": "cloud_public",
            "extracted_data": {
                "keywords": ["ê³µê°œì •ë³´", "ì‹œì¥ë™í–¥", "ì¼ë°˜ë‰´ìŠ¤"],
                "summary": "ì €ë¯¼ê°ë„ ë¬¸ì„œë¡œ ì¸ì‹ë˜ì–´ Gemini Proì—ì„œ í´ë¼ìš°ë“œ ì²˜ë¦¬ë¨",
                "entities": ["ê³µê°œì¸ë¬¼1", "ê³µê°œê¸°ì—…1"],
                "insights": "ì™¸ë¶€ ì •ë³´ ê¸°ë°˜ ê°ê´€ì  ë¶„ì„ìœ¼ë¡œ ì‹œì¥ ì¸ì‚¬ì´íŠ¸ ìƒì„±"
            },
            "security_level": "standard",
            "processing_time": "1.8ì´ˆ",
            "analysis_result": analysis_result
        }
        
        print("âœ… Gemini Pro ì²˜ë¦¬ ì™„ë£Œ")
        return result
    
    def process_with_hybrid(self, text: str, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ (ì¤‘ë¯¼ê°ë„ ë¬¸ì„œ)"""
        print("ğŸ”„ í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ì¤‘...")
        
        # ì‹œë®¬ë ˆì´ì…˜: í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬
        notebooklm_result = self.process_with_notebooklm(text, analysis_result)
        gemini_result = self.process_with_gemini_pro(text, analysis_result)
        
        # ê²°ê³¼ ìœµí•©
        result = {
            "llm_used": "hybrid",
            "processing_type": "combined_analysis",
            "notebooklm_analysis": notebooklm_result["extracted_data"],
            "gemini_analysis": gemini_result["extracted_data"],
            "combined_insights": {
                "keywords": list(set(notebooklm_result["extracted_data"]["keywords"] + 
                                   gemini_result["extracted_data"]["keywords"])),
                "summary": f"í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„: {notebooklm_result['extracted_data']['summary']} + {gemini_result['extracted_data']['summary']}",
                "entities": list(set(notebooklm_result["extracted_data"]["entities"] + 
                                   gemini_result["extracted_data"]["entities"])),
                "insights": "ê°œì¸ ê²½í—˜ê³¼ ì™¸ë¶€ ì •ë³´ë¥¼ ê²°í•©í•œ ì¢…í•©ì  ì¸ì‚¬ì´íŠ¸"
            },
            "security_level": "enhanced",
            "processing_time": "4.1ì´ˆ",
            "analysis_result": analysis_result
        }
        
        print("âœ… í•˜ì´ë¸Œë¦¬ë“œ ì²˜ë¦¬ ì™„ë£Œ")
        return result
    
    def test_hybrid_system(self) -> Dict[str, Any]:
        """í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸"""
        print("ğŸ§ª í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
        
        test_documents = [
            {
                "name": "ê³ ë¯¼ê°ë„_ë‚´ë¶€ì „ëµë¬¸ì„œ",
                "content": "ì´ ë¬¸ì„œëŠ” íšŒì‚¬ì˜ ë¹„ë°€ ì „ëµê³¼ ê¸°ë°€ ì •ë³´ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤. ë‚´ë¶€ ì¸ì‚¬ ì •ì±…ê³¼ ì¬ë¬´ ê³„íšì´ ë‹´ê²¨ìˆì–´ ì™¸ë¶€ì— ìœ ì¶œë˜ë©´ ì•ˆ ë©ë‹ˆë‹¤."
            },
            {
                "name": "ì¤‘ë¯¼ê°ë„_ë¶„ì„ë³´ê³ ì„œ",
                "content": "ì‹œì¥ ë¶„ì„ ë³´ê³ ì„œì…ë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë¶„ì„ ë‚´ìš©ê³¼ ì œì•ˆ ì‚¬í•­ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©°, ì°¸ê³  ìë£Œë¡œ í™œìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            },
            {
                "name": "ì €ë¯¼ê°ë„_ê³µê°œë‰´ìŠ¤",
                "content": "ì¼ë°˜ì ì¸ ë‰´ìŠ¤ ê¸°ì‚¬ì…ë‹ˆë‹¤. ê³µê°œëœ ì •ë³´ì™€ ì°¸ê³  ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìœ¼ë©°, ëˆ„êµ¬ë‚˜ ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì…ë‹ˆë‹¤."
            }
        ]
        
        test_results = []
        
        for doc in test_documents:
            print(f"\nğŸ“„ í…ŒìŠ¤íŠ¸ ë¬¸ì„œ: {doc['name']}")
            
            # ë¯¼ê°ë„ ë¶„ì„
            sensitivity_analysis = self.analyze_sensitivity(doc["content"])
            
            # LLM ë¼ìš°íŒ… ë° ì²˜ë¦¬
            processing_result = self.route_to_llm(doc["content"], sensitivity_analysis)
            
            test_result = {
                "document_name": doc["name"],
                "sensitivity_analysis": sensitivity_analysis,
                "processing_result": processing_result
            }
            
            test_results.append(test_result)
        
        overall_result = {
            "test_timestamp": datetime.now().isoformat(),
            "total_documents": len(test_documents),
            "test_results": test_results,
            "system_status": "operational"
        }
        
        print(f"\nâœ… í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(test_documents)}ê°œ ë¬¸ì„œ ì²˜ë¦¬")
        return overall_result

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ¯ í•˜ì´ë¸Œë¦¬ë“œ LLM ë¼ìš°í„° ì‹œì‘")
    
    # í•˜ì´ë¸Œë¦¬ë“œ ë¼ìš°í„° ì´ˆê¸°í™”
    router = HybridLLMRouter()
    
    # í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_result = router.test_hybrid_system()
    
    # ê²°ê³¼ ì €ì¥
    with open('hybrid_system_test_results.json', 'w', encoding='utf-8') as f:
        json.dump(test_result, f, ensure_ascii=False, indent=2)
    
    print("ğŸ‰ í•˜ì´ë¸Œë¦¬ë“œ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("ğŸ“Š ê²°ê³¼ê°€ hybrid_system_test_results.jsonì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
